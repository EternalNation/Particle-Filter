\documentclass[a4paper, 11pt, twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{graphicx} 
\usepackage{layout} 
\usepackage{geometry}
\usepackage{fancyhdr}
\usepackage{expdlist}
\usepackage{makeidx}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{amsmath,amssymb,amstext}

\fancyfoot[C]{\thepage}%  Spezielle Fusszeile
\begin{document}

\title{\textbf{Tracking von Gesichtern in belebten Umgebungen mit Hilfe eines Partikelfilters}}
\author{ \textit{Kai Wolf} \\ Kai.B.Wolf@student.hs-rm.de\vspace{0.8cm}\\Hochschule RheinMain\\University of Applied Sciences\\Wiesbaden Rüsselsheim Geisenheim}
\date{\today\\[5mm]
\begin{center}
\textbf{Zusammenfassung}\\[2mm]
\begin{minipage}{0.9\textwidth}
Dieses Projekt ist im Rahmen der Vertiefungsveranstaltung Machine Learning im Masterstudiengang Informatik an der Hochschule RheinMain entstanden. Die Veranstaltung fand im Sommersemester 2012 statt und wurde von Prof. Dr. Schwanecke betreut. Die vorliegende Arbeit behandelt das automatisierte Tracking von Personen anhand des Gesichts in belebten Umgebungen. Dabei werden klassifizierte Personen mit Hilfe eines Partikelfilters über mehrere Frames hinweg verfolgt. Der Quelltext zu dieser Arbeit basiert weitestgehend auf der Veröffentlichung von M. Ali, Irshad and Dailey, Multiple human tracking in high-density crowds. Springer Berlin / Heidelberg, 2009, pp. 540-549~\cite{aliMultipleHuman}.
\end{minipage}
\end{center}
} 
\maketitle

\section{Einleitung} % (fold)
\label{sec:einleitung}
Das automatisierte Tracking von Personen in einem Videobild ist eine anspruchsvolle Aufgabe aus dem Bereich Machine Learning. Dabei müssen gleich mehrere Problemstellungen gelöst werden: Erfolgreiche Erkennung von gesuchten Objekten im Videobild, Verfolgung der zuvor entdeckten Objekte über mehrere Frames hinweg und schließlich die Anpassung der Verfolgung unter Einbeziehung des Verhaltens des Objekts~\cite{Yilmaz2006}. 
Das Gesicht einer Person ist im Allgemeinen ein stabiles Feature für die Wiedererkennung~\cite{ViolaRobustObject2001}. Dennoch können bei der Detektion gleich mehrere Probleme auftreten: 
Zum einen kann die Erkennung von Gesichtern aufgrund von Schatten oder starken Reflektionen beeinträchtigt werden, zum anderen können Gesichter gerade in belebten Umgebungen wie Straßen oder Fussgängerzonen durch andere Menschen oder Gebäude teilweise oder ganz verdeckt werden~\cite{aliMultipleHuman}. 
Daher verwendet die vorliegende Arbeit einen schnellen und stabilen Viola-Jones-Klassifikator 


Die vorliegende Arbeit verwendet einen Viola-Jones-Klassifikator zum Erkennen von Gesichtern und einen Partikelfilter für das Tracking über mehrere Frames.

% section einleitung (end)

\section{Bisherige Arbeiten} % (fold)
\label{sec:bisherige_arbeiten}

% section bisherige_arbeiten (end)

\section{Statistische Filter} % (fold)
\label{sec:statistische_filter}

% section statistische_filter (end)

\subsection{Kalman Filter} % (fold)
\label{sub:kalman_filter}

% subsection kalman_filter (end)

\subsection{Partikelfilter} % (fold)
\label{sub:partikelfilter}

% subsection partikelfilter (end)

\section{Gesichtserkennung} % (fold)
\label{sec:gesichtserkennung}

% 1. Start des Programms
% 2. Laden des Viola-Jones adaboost-like cascade classifier (main.cpp)
% 3. Einlesen des Videos frame für frame (main.cpp)
% 4. Im ersten Frame: Start der Gesichtserkennung (adaboostDetect.cpp)
% 4.1. Umwandlung des Frames in Graustufenbild
% 4.2. Resize des Frames (im Code um 10%)
% 4.3. Histogrammausgleich des Bilds
% 4.4. Erkennen der max. Anzahl an Gesichtern im Bild (cvHaarDetectObjects)
% 4.5. Falls erkanntes Gesicht innerhalb vorgegebener Parameter( Größe),
%      speichern von Rechteckkoordinaten rund um das Gesicht
% 4.6. Speichern aller Regionen, in denen Gesichter entdeckt wurden
% 5. Initialisierung des Trackers (tracker.cpp)
% 5.1. Umwandlung des akt. Frames in HSV-Farbschema
% 5.2. Initialisierung des Partikelfiters (particleFilter.cpp)
%
% 5.3. Für jedes entdeckte Gesicht: Initialisierung eines Bewegungspfads mit
%      Speichern in welchem Frame Bewegungspfad gesetzt wurde, Gewicht 1,
%      Histogramm der entsprechenden Region um das Gesicht und mit KO des
%      Partikelzentrums



% section gesichtserkennung (end)

\section{Evaluation} % (fold)
\label{sec:evaluation}

% section evaluation (end)

\section{Zusammenfassung} % (fold)
\label{sec:zusammenfassung}

% section zusammenfassung (end)

\bibliographystyle{plain}
\bibliography{/Users/kai/Documents/library}

\end{document}